---
title: "CondProb new script"
author: "Roger Day"
date: "2025-05-13"
output:
  html_document:
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

$$
\newcommand{\alldata}{\space 
  \color{red}{\mathrm{{all{\space}data}} \space }}
\newcommand{\OR}{\space \mathrm{or}\space}
\newcommand{\AND}{\space \mathrm{and}\space}
\newcommand{\RR}{\color{red}{R1 \AND R2}}
$$

```{css}
table {
  margin: auto;
  border-top: 1px solid #666;
  border-bottom: 1px solid #666;
}
table thead th { border-bottom: 1px solid #ddd; }
th, td { padding: 10px; }
```


##  ##Setup

```{r defaults}

CondProb_folder  = '"/Users/Roger/Sites/Bioinf-2118-2018-website/N-files-for-handouts/CondProb video"'

options(digits=4)
priorFor4 = c(0.9,0.10, 9, 90)/100

names(priorFor4) = c('dD', 'hD',	'iD',	'noD')
longgroupnames = c(dD='detectable', hD='hidden',	
                   iD='imposter',	noD='no disease')
pr_positive_given_group = c(90,10,50, 10)/100
names(pr_positive_given_group) = 
  c('dD', 'hD',	'iD',	'noD')
pr_dist_given_group = rbind(pr_positive_given_group, 1 - pr_positive_given_group) 
rownames(pr_dist_given_group) = c('pos', 'neg')
normalize= function(x)  x/sum(x)

source('makePosteriorSequence.R')
```
## ##Intro

Welcome to Statistics Beautiful.
Today: a pet turtle in the clutches of a child, a prisoner's picnic gone bad, alarming claims like there's visitors from outer space, or "yadayada Hillary Clinton yadayada"....or, birds aren't real!
& how to combine repeated medical tests. All to understand better-- How do we use the SECOND bit of suggestive information, and why does conditional independence matter? And did I mention machine learning? So, strike up the band for the Bayesian dance! 



There's what you know. We'll call that data.   

And there is something you want to know. 

We'll call that the unknown truth, the true state... is the answer ALIENS YES or NO?, is the statement TRUE or FALSE?, is the SICKNESS PRESENT or ABSENT?  

In episode 1, we learned how you start with some belief about the true state. A belief expressed as probabilities. Or even better, as *odds*.

Then you use new data to refine that initial belief.

Well odds is just a different way of describing a probability P. Instead of P, think about P over one minus P. Same information, in fact P equals odds over one plus odds. Two to one odds means the probability P  is two divided by two plus one, which is 2/3. Probability of 2/3 is an odds of 2/3 over 1/3, and we're back to odds=2. A probability is between zero and one, and an odds is between zero and infinity.
Refresh yourself at this link here if you want. . 

OK. An alarming possibility, like visitors from outer space, or "yadayada Hillary clinton yadayada"...., 
or "birds aren't real".
They tell me, "Do your own research. OK, internet here I come.
More on that later.

Meanwhile, suppose I start with a very LOW odds that the alarming possibility is true.

I'm after all a reasonable human.

Now I get deluged by a flurry of pieces of evidence supporting the doctrine. Each one pushes up my belief, my confidence in the alarming possibility, my personal credence, my personal probability.

## ##Multiply

The Reverend Thomas Bayes tells me.
I'll just multiply the current odds, the "prior odds", by the ratio of the two different explanations of how you could have got the data. 
If it's TRUE, would I get this news report?  
And if it's BS, would I get this news report?
That's called the likelihood ratio for the data:


$$
\begin{aligned}
LR & = Likelihood \space Ratio \\
& =\frac{
Probability \space that \space you'd \space get \space this \space data \space if \space the \space crazy \space idea \space is \space TRUE}
{Probability \space that \space you'd \space get \space this \space data \space if \space the \space crazy \space idea \space is \space BS}
\end{aligned}
$$


where "*BS*" is short for... mmm...  "*NOT true*".

Here's a maybe more serious example. Switch to a medical diagnosis setting.

## ##Medical table

![](table_for_+D_-D.png)

![](/Users/Roger/Sites/Bioinf-2118-2018-website/N-files-for-handouts/CondProb video/app_Picture1.png)

A link to this app is in the Dungeon, also to Episode 1, which walks you through how to use it.
The prior odds is one percent, quite low. This diagnosis seems like a long shot going in the door.  
The patient has a positive test result.
If the patient is a +D, yes it's the disease, then the probability is the sensitivity, 90%. 
If the patient is a -D, no it's not the disease, then the probability is the 1 minus the specificity, just 9%.  The LR is 90/9.

It is high, it's 10, so getting a positive is far more likely if the person is Sick, but now multiply the odds by the LR and you've only boosted the odds up from 1 to a hundred to 1 to 10, the probability only increases to 9%, which is 1 divided by (odds plus 1).

Ah, but here comes more information, more data!  What do we do with THAT?

Repeat the test. Suppose you get the same answer every time.  

$R1$ is Positive, $R2$ is positive, $R3$ is  positive, $R4$ is positive. 

Just multiply by the new data's likelihood ratio. Right?  WRONG! Aw, man!


Let's pretend it's ok for now. Multiplying by the same LR again and again.
That's the same as adding the same *log LR* every time, because the logarithm turns multiplying into adding. These little up-arrows are the same length. So again let's start with odds of 1 to a hundred, probability 9%. The first positive test R1 brings the chance up only to 9%.  The second one, R2, jacks it up to a half. R3 brings it to 91%, and R4 to 99%.

#### INSERT VIDEO of 3 scales

Just look at all that evidence mount up! It seems that $+D$, the disease is present, is nearly certain now.

```{r, results='asis'}
### The nice case. Cond Indep, all good.
  print(makePosteriorSequence(dropZeroGroups = TRUE,
    prob_pos_given_group = c(0.9, 0, 0, 0.09),
    priorFor4 = c(.01,0,0,.99)
    )
    )
```

( The app that makes this table is yours to play with. Link is in the dungeon.)


## ## Careful

We gotta be careful, though.
The general principle, the key idea is: always condition on ALL you know, all together. Like this:

$$
\begin{aligned}
Odds(+D|\alldata) & =\frac{Pr(+D|\alldata )}{Pr(-D|\alldata )}\\
& =\frac{Pr(\alldata \AND +D)/Pr(\alldata )}
      {Pr(\alldata \AND -D)/Pr(\alldata )}\\
& = \frac{Pr(\alldata |+D)}{Pr(\alldata |-D)}\ \frac{Pr(+D)}{Pr(-D)}\\
& = LR(\alldata)\times Odds(+D)
\end{aligned}
$$

In this case, just taking the first two reports, that becomes

$$
\begin{aligned}
Odds(+D|\RR) & =\frac{Pr(+D|\RR)}{Pr(-D|\RR)}\\
& =\frac{Pr(\RR \AND +D)\quad/\space Pr(\RR)}
      {Pr(\RR \AND -D)\quad/\space Pr(\RR)}\\
& = \frac{Pr(\RR|+D)}{Pr(\RR|-D)}\ \frac{Pr(+D)}{Pr(-D)}\\
& =LR(\RR)\times Odds(+D)
\end{aligned}
$$

The celebrated 3Blue1Brown hinted that this at the end of an excellent video on Bayesian method.
![](/Users/Roger/Sites/Bioinf-2118-2018-website/N-files-for-handouts/CondProb video/3b1b-bayes-factors.png)
$$
\newcommand{\RR}{\color{red}{R1 \AND R2}}
\newcommand{\yellowD}{\color{blue}{D}}
\newcommand{\greenR1}{\color{green}{R}}
\newcommand{\blueR2}{\color{blue}{R{2}}}
TEST \RR
$$
$$
O(\yellowD | \greenR1 , \blueR2 )= O(\yellowD )\box{\frac{{(\greenE1 | \yellowD)} {(\greenE1 | \notD)}}} 
$$

(He has E for event, we have R for report. Nice colors, Mr. Sanderson.) 
The 2nd Bayes factor (what we're calling likelihood ratio) conditions not just on the new data E2 but on the previous data E1 also. 


If we are lucky, R1 and R2 are CONDITIONALLY INDEPENDENT. Getting the right answer for $R1$ doesn't increase or decrease the chance of a right answer for $R2$. And that's good, it means R2 provides new information.
Just keep multiplying by the next *LR*.

$$
\begin{aligned}
LR(\RR) &= 
\frac{Pr(\RR|+D)}{Pr(\RR|-D)}\\
&= \frac{Pr(R1|+D) \quad Pr(R2|+D)}{Pr(R1|-D) \quad Pr(R2|-D)}\\
&= LR(R1)  \quad  \quad \times  \quad  \quad LR(R2)
\end{aligned}
$$
The numerator splits, and the denominator splits. 
But, careful,  this only works if TWO conditional independence claims are true... one for the numerator ($+D$) and one for the denominator ($-D$).

## ## Oh no,

Here is the same probability table. Same sensitivity, same specificity, same prior initial chance of Disease.
![](table_for_+D_-D.png)

but something sneaky lurks underneath



```{r, results='asis'}
  print(makePosteriorSequence(
    priorFor4 = c(0.009, 0.001, 0.09, 0.90),
    prob_pos_given_group = c(1,0,1,0) , marginalize=TRUE))
```

A sequence of repeated  tests don't keep jacking up the probability.
After the first test, which raised the chance from 1% to 9% just as before, none of the next 4 deliver any new information.
Why?


 
## ## What's lurking: 4 groups

Here, the positive tests include  GENUINE false positives, because the patient has some OTHER condition, that the test is picking up when we don't want it to.  A misdiagnosis. An imposter. In the lingo, the test is not *specific* enough. "$iD$", means an imposter, when the real deal is "$dD$" for detectable disease.

What's as bad, there can be GENUINE false negatives. Some patients WITH the target disease might have a variant of the disease so that, in the lingo, the test is not sensitive enough. *Hidden disease*. "$hD$".
Sometimes called "occult disease", but that sounds too much like being possessed by demons!

Everybody with the disease we want to detect is $+D$, either $dD$ or $hD$.

Everybody who we want to get a negative test for is $-D$, either $noD$ or $iD$.

So $+D$ splits into two types of patients:  true positives $dD$ and false negatives $hD$.
And $-D$ splits into two types of patients: true negatives $noD$ and false positives $iD$.

So, 4 categories instead of 2. 

```{r group names, results='asis'}
print(
  knitr::kable(format='html', data.frame(short_name=c('dD', 'hD', 'iD', 'noD'),
           long_name = as.vector(c(dD='detectable', hD='hidden',	
                   iD='imposter',	noD='no disease')), 
           test_result=c('true positive', 'false negative',
                         'false positive', 'true negative')
))
)
```

## what we want, what we get


```{r what we want what we get, results='asis'}
print(
  knitr::kable(format='html', 
               data.frame(
                 short_name=c('dD', 'hD', 'iD', 'noD'),
           long_name = as.vector(c(dD='detectable', hD='hidden',	
                   iD='imposter',	noD='no disease')), 
           test_result=c('true positive', 'false negative',
                         'false positive', 'true negative'),
           `what_we_want`=c('positive', 'positive', 'negative', 'negative'),
           `what_we_get`=c('CORRECT!', 'WRONG', 'WRONG', 'CORRECT!')
))
)
```


## ## 4 groups distribution

Here is the behind-the-veil full truth. 
Each category of patients has its own 
*Probability of a Positive Test*.

```{r image test,echo=FALSE }
##  Dead end.  This 
# does work in a chunk but not in an inline context.
#require(imager,quietly = TRUE)
images = "../N-files-for-handouts/CondProb video/"
#plot(load.image(paste0(images, "table_for_dD_hD_iD_noD.png"))) 
```
## ## 4 categories probability table

![](../N-files-for-handouts/CondProb video/table_for_dD_hD_iD_noD.png)


We actually don't have prior information for the 4 groups. In fact, we probably don't even know that the sneaky ones, the hiddens and the imposters,  exist. 

Looking at the bottom two rows, the probabilities from the first table showing probabilities for only +D and -D are still correct, but we cannot see the breakdown between dD and hD, between iD and noD.

The hidden $hD$ and the imposters $iD$ are explanations for false positives and false negatives. Successive false results often share the same cause. Sometimes, two false positives in a row occur because they share the patient, and the patient has an imposter condition that explains both false positives. If you only knew that, you wouldn't be fooled so easily.

Too bad we don't know that.

After time passes, following up on the patients, we may learn the truth, which patients really had the disease, so we learn which of the test results had been false.
Sometimes we can do biomedical research, learn that these subgroups exist, and find biomarkers for them.





```{r, asis}
priorFor4 = c(0.9,0.10, 9, 90)/100
names(priorFor4) = c('dD', 'hD',	'iD',	'noD')
pr_positive_given_group = c(90,10, 50, 10)/100
names(pr_positive_given_group) = 
  c('dD', 'hD',	'iD',	'noD')
###  unused?
```

## ## dD and hD = +D

Meanwhile, Let's  suppose we have just two test results, $R1 = positive, R2 = positive$. If we pretended that the two tests were independent conditionally on $+D$, we'd get

##  Assuming conditional independence for +D

$$
\begin{aligned}
Pr(\RR \space | \space +D) 
        & = Pr(positive \space | \space +D) {^2} \\
        & = 0.9^2 \\
        & = 0.81
\end{aligned}
$$

##  Assuming conditional independence for all 4 subgroups
But if conditional independence IS true for each of the FOUR subgroups of patients, 
$$
\begin{aligned}
Pr(positive, positive \space | \space group \space G) 
        & = Pr(positive \space | \space \space group \space G) {^2} \quad 
\end{aligned}
$$
In particular, for G equals dD and hD. 
Then

$$
\begin{aligned}
Pr(\RR \space | \space +D) & = Pr(\RR \space | \space dD) \quad {Pr(dD | +D)} \\
        & + Pr(\RR \space | \space hD) \quad  {Pr(hD | +D)} \\  
        & = Pr(positive \space | \space dD) {^2} \quad  {0.009/0.01} \\
        & + Pr(positive  \space | \space hD) {^2} \quad  {0.001/0.01} \\
        & = 1.0^2 * 0.009/0.01 + 0.0^2 * 0.001/0.01  \\
        & = 0.9
\end{aligned}
$$

That's different.

That the true probability 90% is larger than 81% makes sense.  
After the first positive test result, only dD and iD are possible. And they both GUARANTEE that the next result will be positive... a true positive for dD and a false positive for iD.

After the 1st report, the next bunch contribute no new information. $Pr(R2 = positive | R1 = positive) = 1$ whether the patient is a true detectable dD or an imposter iD.

Any data whose probability equals one no matter what the truth is, is useless for discovering the truth!   

For the bottom part of LR,
$$
\begin{aligned}
Pr(\RR \space | \space -D) & = Pr(\RR \space | \space dD) \quad {Pr(noD | -D)} \\
        & + Pr(\RR \space | \space hD) \quad  {Pr(iD | -D)} \\  
        & = Pr(positive \space | \space noD) {^2} \quad  {0.09/0.99} \\
        & + Pr(positive  \space | \space -D) {^2} \quad  {0.90/0.99} \\
        & = 1.0^2 * 0.09/0.99 + 0.0^2 * 0.90/0.99  \\
        & \approx 0.09
\end{aligned}
$$

So the true likelihood ratio is 0.9/0.09 = 10 instead of 0.81/(0.1^2)=81.
Far weaker evidence.

The LR for R1 alone is sensitivity/(1-specificity) = 10. 
So sure enough, the second report added no new information.


## ## 2 or more negatives

What if you get all NEGATIVE tests. Maybe the doctor really really really doesn't want to miss it. 

(Actually, it could be that as time passes a hidden disease becomes detectable. That's why every few years we repeat some cancer screening tests.  That's an important case, but we'll set that aside for now.)

```{r table for repeated negative tests, results='asis'}
  print(makePosteriorSequence(dataSequence = c(2,2,2,2),
    priorFor4 = c(0.009, 0.001, 0.09, 0.90),
    prob_pos_given_group = c(1,0,1,0) , marginalize=FALSE))
```
Once again, after the first test, the rest are guaranteed to provide no further information. Here is the full story.

The negatives wipe out the detectable dD's. But not the hidden ones, hD.

Now, suppose there are no imposters.

Ideally you could carve up the population of patients into groups using explanations for why the groups differ. Then the only thing remaining would be pure chance mistakes, not explained by something about the particular patient. 



![](../N-files-for-handouts/CondProb video/table_for_dD_hD_iD_noD-switcheroos.png)


## ## Media bubbles

And so we return to conspiracy theories and algorithms.

The algorithm recommends a video that shows that 

![birds are not real!](/Users/Roger/Sites/Bioinf-2118-2018-website/N-files-for-handouts/CondProb video/birds-are-not-real-1.png){width=20%}

My guess? They are all just Hillary Clinton wearing feathers.

Naa, that's silly.  But kind of fun. So you watch the video. The algorithm feeds you another one, another 'proof'. Your posterior probability goes up a bit. Then another, and another.  

###### INSERT video of 3 scales

All these "independent" pieces of evidence.
But are they independent? Really? 
No, they all just replicate, with modifications, a common origin.
ONe man's prank.

###### INSERT video of 3 scales showing common origin

So friends, be tolerant to our neighbors in media bubbles.
They don't know about conditional independence.

## mention Ground News?

## ## Factoring joint distributions

Let's dive in deeper.  (Or, 'delve' in, as ChatGPT would say.)

Suppose you have a bunch of, say, ten random quantities $R1, ... , R10$.
You can ALWAYS write their joint distribution, in a monstrous string.
$$
\color{blue}{Pr(R1)} \times Pr(R2 | R1) \times Pr(R3 | R1, R2)...  \times Pr(R10 | R1, R2, ... R9)
$$
Everything is connected to everything. The order is arbitrary.  But you need a starting point, in this case $\color{blue}{Pr(R1)}$ , that is UNconditional on anything else.

## ## Causal diagrams and colliders

## Markov chain
Complicated! But with conditional independence, way simpler.


$$
Pr(R1) \times Pr(R2 | R1) \times Pr(R3 | R2)...  \times Pr(R10 | R9)
$$


What happens as you go get the next report depends only on the current report Everything before is forgotten.  So at the end, $Pr(R10 | R9)$ instead of $Pr(R10 | R1,R2,...,R9)$

This chain of influence is called a Markov chain.

This *pet turtle* decides where to go next after its owner spins it around randomly without picking it up and moving it. It knows where it is, but where it was before is forgotten.

#### INSERT turtle video.


## ## Causal analysis

Diagrams with boxes and arrows makes you think of causes and effects. In another video I'll deal with how conditional independence diagrams can, and cannot say about cause and effect.

## ## Monte Carlo Markov Chain 

Getting back to the general case,
$$
\color{blue}{Pr(R1)} \times Pr(R2 | R1) \times Pr(R3 | R1, R2)...  \times Pr(R10 | R1, R2, ... R9)
$$

Remember you need a starting point. One of the 10 random reports, you have to know its *marginal* probabilities ignoring all the others, *unconditional* all the others. If you don't know ANY unconditional distribution, do you give up? No! Techniques like Monte Carlo Markov Chain are wildly popular. They contribute to heavy duty data methods like Machine Learning. 

Fodder for a future video.

Now you're ready for more Professor Beautiful tuba music.





